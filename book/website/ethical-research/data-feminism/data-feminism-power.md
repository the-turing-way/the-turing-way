(er-data-feminism-c1)=

# Chapter 1: Examining Power

Here are some main ideas from this chapter on examining power. 

(er-data-feminism-c1-keypoints)=
## Key Points

- **Understanding Influence**: It is essential to recognise how racism, sexism, and privilege shape oppression.
- **Naming Oppression**: Examining power involves identifying and explaining the oppressive forces ingrained in our daily lives.

(er-data-feminism-c1-powerdomains)=
## Domains of Power

Power systems can be configured and experienced across [four domains](https://data-feminism.mitpress.mit.edu/pub/vi8obxh7#nkiyehtj87r):

1. **Structural**: The institutional framework (The policies and laws that exist).
2. **Disciplinary**: Regulatory and normative practices (How these policies/laws are enforced).
3. **Hegemonic**: Political and social contexts (How the culture and media influence and contribute to oppression).
4. **Interpersonal**: Day-to-day interactions (Individual experiences).

(er-data-feminism-c1-intersectionality)=
## Intersectionality

Dimensions such as gender, race, sexuality, geography, and ability can lead to unjust oppression or unearned privilege across these four domains.

(er-data-feminism-c1-questions)=
## Critical Questions

To understand how power unfolds in and around data, consider:

1. **Who is engaged in data science work (and who is not)?**
2. **Whose goals are prioritised in data science (and whose are not)?**
3. **Who benefits from data science (and who is overlooked or harmed)?**

These questions are uncomfortable but necessary as they reveal that certain groups disproportionately benefit from data science while others are disproportionately harmed.

(er-data-feminism-c1-dominance)=
## The Problem of Dominance

When data teams are predominantly from dominant groups, their perspectives unduly influence decision-making processes.

(er-data-feminism-c1-privilege)=
## Privilege Hazard

This phenomenon occurs when those in the most privileged positions (with good education, respected credentials, professional accolades) wield disproportionate influence.
This hazard is more harmful in aggregate as it permeates structural, disciplinary, and hegemonic domains.

(er-data-feminism-c1-threats)=
## The Threat of AI

Social scientist, [Kate Crawford](https://katecrawford.net/), argues that the biggest threat from AI systems is not their intelligence but their potential to embed sexism, racism, and other forms of discrimination into our digital infrastructure.


Researchers have shown that [images of immigrants, abused children, and deceased individuals have been used to train software without consent](https://slate.com/technology/2019/03/facial-recognition-nist-verification-testing-data-sets-children-immigrants-consent.html), raising serious ethical issues.

(er-data-feminism-c1-datagoals)=
## Current Data Goals

Data science is predominantly used for:

1. **Profit (for a few)** - seen in corporations
2. **Surveillance (of the marginalised)** - used by governments
3. **Efficiency (amidst data scarcity)** - prioritised by research institutions/universities such as optimising algorithms and models to work with limited data

(er-data-feminism-c1-goals)=
## The Goal of Examining Power

The essence of examining power is not only to understand power but also to challenge and change it.

(er-data-feminism-c1-casestudies)=
## Case Studies

- **[Serena Williams and the Healthcare System](https://edition.cnn.com/2018/02/20/opinions/protect-mother-pregnancy-williams-opinion/index.html)**: Illustrates racial bias in healthcare.
- **[Joy Buolamwini and MIT's Facial Recognition System](https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212)**: Highlights issues of bias in technology.
- **[CloudWalk and Zimbabwe](https://qz.com/africa/1287675/china-is-exporting-facial-recognition-to-africa-ensuring-ai-dominance-through-diversity)**: Raises ethical concerns about data sharing and human rights.

(er-data-feminism-c1-reading)=
## Further Reading

- **[Algorithms of Oppression by Safiya Umoja Noble](https://www.goodreads.com/book/show/34762552-algorithms-of-oppression)**: Explores how gender and racial biases in information systems are complex and often rooted in the data and models created by small, homogenous groups.
- **[Artificial Unintelligence by Meredith Broussard](https://www.goodreads.com/book/show/36722634-artificial-unintelligence)**: Goes into the limitations and misunderstandings embedded within AI systems.
- **[Invisible Women by Caroline Criado PÃ©rez](https://www.goodreads.com/book/show/41104077-invisible-women)**: Discusses gender biases in data.
